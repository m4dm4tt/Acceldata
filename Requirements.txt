Mail as recieved from Acceldata:
--------------------------------
We at Acceldata want to optimize SQL queries on the fly. 
We would like to implement a minimal query parser that allows us to apply simple optimization rules for auto-tuning queries.

Given a SQL query, Your query parser/analyzer should be able to

Count number of Subqueries
List of Subqueries with their Aliases.
Get a list of Tables used in each Subquery along with table aliases
Get a list of any Between clauses, order by clauses and limit clauses
Get a List of Joins used Per sub query along with the join types


Requirement
-----------
Given a SQL Query,

1) Count number of sub-queries.
	DONE
2) List of sub-queries with their aliases.
		DONE
		ALIAS PENDING
3) List of tables used in each sub-query along with table aliases.
		DONE
4) List of BETWEEN, ORDER BY and LIMIT clauses.
		LIMIT DONE
		BETWEEN HAS TWO BUGS:
		ORDER BY HAS SAME BUG
			
5) List of joins per sub-query along with join type.


Language of choice
------------------

Bash is out since this project involves much more than simple text search. There is need for tokenization. Python has a good language parser module(NLTK).
We also need positional traversal of queuing/stack to arrive at index positions, which bash cannot handle but Python deque can.



Setup
-----

1) Install python 3.8 for windows and ensure its added to the PATH
2) Install nltk: type: pip install nltk
3) In python shell, type: import nltk
4) In python shell, type: nltk.download('all')
